<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Tensorics Java Library Website">

  <title>Tensorics - Tensorics Manual</title>

  <link rel="canonical" href="http://tensorics.github.io//projects/tensorics-core/manual/">

  <link rel="preload stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
  <link rel="preload stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
  <link rel='preload stylesheet' href='//fonts.googleapis.com/css?family=Open+Sans:300,700'>
  <link rel="preload stylesheet" href="/css/coderay.css">
  <link rel="preload stylesheet" href="/css/asciidoctor.css">
  <link rel="preload stylesheet" href="/css/main.css">
</head>

<body>
  <div class="container-fluid">
    <div class="row">
      <div class="col-md-12">
        <div class="site-header">
  <h1><span><a class="site-title" href="/">Tensorics</a></span></h1>
</div>

      </div>
    </div>
  </div>

  <div class="container">
    <div class="row">
      <div class="col-md-3 col-s-12">
        <nav>
<ul class="nav nav-pills nav-stacked">
	
	
		

		
			
				<li role="presentation" ><a class="page-link" href="/">Home</a></li>
			
		
			
		
	
		
			<li><p class="nav-group-title">Tensorics Core</p></li>
		

		
			
				<li role="presentation" class="active"><a class="page-link" href="/projects/tensorics-core/manual/">Tensorics Manual</a></li>
			
		
			
				<li role="presentation" class="active"><a class="page-link" href="/projects/tensorics-core/manual/">Tensorics Manual</a></li>
			
		
			
				<li role="presentation" ><a class="page-link" href="/projects/tensorics-core/quickstart/">Tensorics Quickstart Guide</a></li>
			
		
			
				<li role="presentation" ><a class="page-link" href="/projects/tensorics-core/todo/">Tensorics Todo</a></li>
			
		
	
		
			<li><p class="nav-group-title">Tensorics expression</p></li>
		

		
			
				<li role="presentation" ><a class="page-link" href="/projects/tensorics-expression/manual/">Tensorics Expression Manual</a></li>
			
		
	
</ul>
</nav>

      </div>
      <div class="col-md-9 col-s-12">
        <div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p>Tensorics is a java framework for data processing of multidimensional data.
The core object is a Tensor which represents a collection of values of arbitrary
types, which are addressed by coordinates in an N-dimensional space. The framework
provides several core features, which make it easy to work with big amounts of
numerical data and drastically simplify repetitive tasks:</p>
</div>
<hr>
<div class="ulist">
<ul>
<li>
<p>Tensors of arbitrary dimensionality as central object.</p>
</li>
<li>
<p>Tensors can have elements of any (java) type.</p>
</li>
<li>
<p>Structural and numerical operations on tensors.</p>
</li>
<li>
<p>Java internal DSL (fluent API) for all operations on scalars and tensors.</p>
</li>
<li>
<p>Quantities (value - unit pair).</p>
</li>
<li>
<p>Full support for Tensors of quantities.</p>
</li>
<li>
<p>Error and Validity propagation for quantities and tensors of quantities.</p>
</li>
<li>
<p>Scripting of all functionality with deferred execution, which opens the
possibilities for parallel processing and massive distribution of calculations.</p>
</li>
</ul>
</div>
<hr>
<div class="admonitionblock important">
<table>
<tr>
<td class="icon">
<i class="fa icon-important" title="Important"></i>
</td>
<td class="content">
Both, the current implementation as well as this document, are work in progress.
The main purpose of the actual version is provide some functionality of every of the above
mentioned categories and proofing the concepts of their interplay. Still, already the available
subset of features should have useful applications in many contexts. Almost no effort put on
profiling and performance optimization. Therefore, it might well be that some operations are
quite inefficient and/or memory consuming for big objects. Such improvements are definitely planned
for later iterations. Any contributions are welcome.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="introduction"><a class="anchor" href="#introduction"></a>Introduction</h2>
<div class="sectionbody">
<div class="paragraph">
<p>A common need in applications that manipulate numerical data is to organize them in data structures which allow easy transformations and calculations. This paper describes the ensorics library for the Java programming language which provides several, complementary concepts to ease such tasks. Despite the libraries name is derived from "tensor", it contains several additional concepts which complement each other.
The features are designed to work smoothly together, but each of them can of course also be used stand-alone. In the following sections, we give a short overview on the different concepts, together with some explanatory code examples.</p>
</div>
<div class="sect2">
<h3 id="tensors"><a class="anchor" href="#tensors"></a>Tensors</h3>
<div class="paragraph">
<p>The name "Tensorics" is derived from "Tensor".
Loosely speaking, a tensor in mathematics is a multidimensional data structure,
whose dimensionality is given by the number of indices.
A tensor of dimensionality N contains a value for each N-tuple of index values.
Tensors in mathematics are usually denoted by noting their elements with a full set of indices.
E.g. an element of a 3-dimensional tensor \tens{A} would be denoted as \tensel{a_{ijk}}. Each index ($i,j,k$) can potentially have its own range (e.g. $1 &#8656; i &#8656;  M_i$, $1 &#8656; j &#8656;  M_j$, $1 &#8656; k &#8656;  M_k$).</p>
</div>
<div class="paragraph">
<p>Another way to see this is that a tensor has a value for each point in an N-dimensional integer space. In the above notation a dimension is identified by the position of the respective index, and the coordinate in that dimension is given by the value of the index.
These mathematical concepts are extremely useful, especially when it comes to operations on such tensors (as we see in later sections). Therefore, \tensorics{} borrows many concepts from mathematics. At the same time it translates them into the  programming language in a way that is aimed to form a powerful data structures which encourages readable code as much as possible and helps avoiding confusion and mistakes. For this reason, we use the word "Tensor" in an even sloppier manner.</p>
</div>
<div class="paragraph">
<p>The main particularity of a tensorics tensor is that a dimension is not identified by the position of the index, but by a java type (class). Instances of the respective type we denote as \emph{coordinates}. A point within the N-dimensional coordinate space is then defined by a set of objects (instances of coordinate classes), of which each type must be exactly once.  This key concept allows easier and less error-prone usage (because the order of the coordinates/indices is not relevant) and still leads to readable code.</p>
</div>
<div class="paragraph">
<p>A \tensorics{} tensor has one type parameter, the type of the values it contains, usually denoted as \code{&lt;V&gt;}. Therefore, the tensor data structure can be used as container for any Java type. However, some operations on the tensors will be only possible for certain value types (e.g. mathematical operations).</p>
</div>
</div>
<div class="sect2">
<h3 id="an_example"><a class="anchor" href="#an_example"></a>An Example</h3>
<div class="paragraph">
<p>Since tensorics concepts and syntax are best explained in a practical walk-through, we will use the following example throughout the subsequent sections:</p>
</div>
<div class="paragraph">
<p>Consider weather analysis: A data set consists of weather data from different cities and times. The class City and Time are defined and some constants are instantiated.  Temperature values are stored in a tensor of doubles, for example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">City SF = City.ofName(<span class="string"><span class="delimiter">&quot;</span><span class="content">San Francisco</span><span class="delimiter">&quot;</span></span>);
City LA = City.ofName(<span class="string"><span class="delimiter">&quot;</span><span class="content">Los Angeles</span><span class="delimiter">&quot;</span></span>);

<span class="predefined-type">Time</span> T1 = <span class="predefined-type">Time</span>.of(<span class="string"><span class="delimiter">&quot;</span><span class="content">2017-01-01 15:00</span><span class="delimiter">&quot;</span></span>);
<span class="predefined-type">Time</span> T2 = <span class="predefined-type">Time</span>.of(<span class="string"><span class="delimiter">&quot;</span><span class="content">2017-01-02 15:00</span><span class="delimiter">&quot;</span></span>);

Tensor&lt;<span class="predefined-type">Double</span>&gt; degrees;
<span class="comment">/* creation omitted */</span></code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="accessing_values"><a class="anchor" href="#accessing_values"></a>Accessing Values</h3>
<div class="paragraph">
<p>Assuming the above constants, we can then simply get temperature values from the tensor:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Double</span> t = degrees.get(T1, SF);</code></pre>
</div>
</div>
<div class="paragraph">
<p>As visible here, this looks very similar to getting values from a map, with the following important differences:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The get method of a tensor accepts N arguments, one for each dimension.</p>
</li>
<li>
<p>The get method of a tensor never returns <code>null</code>. It will throw an appropriate exception in case there is no value available in the tensor for the given set of coordinates.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In general, it shall be noted that all methods within the tensorics library are designed to fail fast. This is particularly important because \tensorics{}, due to its flexible API, cannot rely on compile-time checks in many cases and thus some errors only appear at runtime.</p>
</div>
<div class="paragraph">
<p>The set of N coordinates is called a <em>position</em> in tensorics. Thus, the code from the above listing is equivalent to</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Position</span> position = <span class="predefined-type">Position</span>.of(T1, SF);
<span class="predefined-type">Double</span> t = degrees.get(position);</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="main_entry_point"><a class="anchor" href="#main_entry_point"></a>Main Entry Point</h3>
<div class="paragraph">
<p>The interfaces of tensorics objects are kept very slim and usually only provide the absolutely necessary methods. All the other operations on these objects is based on static methods operating on them. The main entry point for these methods (containing all the methods which are not specific to certain value types) is the class \code{Tensorics}. This class contains also, for example, a delegation method to the \code{Position.of()} method:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Position</span> position = Tensorics.at(T1, SF);
<span class="comment">/* with static import: */</span>
<span class="predefined-type">Position</span> position = at(T1, SF);</code></pre>
</div>
</div>
<div class="paragraph">
<p>Using a static import for this, allows concise code which will be particularly important when creating tensors.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
In all the following code examples, we assume that, whenever there is a plain method call, then it is a static method from the <code>Tensorics</code> class (or in other words that <code>Tensorics.</code> is imported statically).
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="creating_tensors"><a class="anchor" href="#creating_tensors"></a>Creating Tensors</h3>
<div class="paragraph">
<p>All currently available implementations of tensors are immutable. The usual way to create them is through builders. For example, to create our temperature tensor and put 4 values into it, we would have to do something like:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Tensor&lt;<span class="predefined-type">Double</span>&gt; degrees =
    builder(City.class, <span class="predefined-type">Time</span>.class)
         .put(at(SF, T1), <span class="float">12.5</span>)
         .put(at(SF, T2), <span class="float">14.2</span>)
         .put(at(LA, T1), <span class="float">17.5</span>)
         .put(at(LA, T2), <span class="float">19.2</span>)
         .build();</code></pre>
</div>
</div>
<div class="paragraph">
<p>Again, the syntax is very similar to building an immutable map. And indeed this is another way how a \tensorics{} tensor can be seen: As a map from position to a value - and it can be transformed into one:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Map</span>&lt;<span class="predefined-type">Position</span>, <span class="predefined-type">Double</span>&gt; degreesMap =         mapFrom(degrees);</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="scalar"><a class="anchor" href="#scalar"></a>Scalar</h3>
<div class="paragraph">
<p>A tensor can have zero dimensions. This particular tensor we denote as <em>scalar</em> in \tensorics{}. It has exactly one value at the position <code>Position.empty()</code>. A scalar can simply be created using the static factory method</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Scalar&lt;<span class="predefined-type">Double</span>&gt; scalar = scalarOf(<span class="float">2.5</span>);</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="structural_operations"><a class="anchor" href="#structural_operations"></a>Structural Operations</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Up to now, we were simply using a tensor as a kind-of map with combined keys. However, the real power is unleashed only when it comes to transformations. For this it is useful to understand on additional concept:</p>
</div>
<div class="sect2">
<h3 id="shape"><a class="anchor" href="#shape"></a>Shape</h3>
<div class="paragraph">
<p>Just like a map has its set of keys, a tensorics tensor has a shape. It basically describes the structure of the tensor, without its values. Basically it contains the following information:
- The dimensions of the tensor (e.g. <code>Time.class</code> and <code>City.class</code> in the above example) and
- The available positions in the tensor.</p>
</div>
<div class="paragraph">
<p>The shape can be retrieved from the tensor and used for our example like the following:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Shape</span> shape = degrees.shape();

<span class="predefined-type">Set</span>&lt;<span class="predefined-type">Class</span>&lt;?&gt;&gt; dims = shape.dimensionSet();
<span class="comment">/* Contains Time.class and City.class */</span>

<span class="type">int</span> dim = shape.dimensionality();
<span class="comment">/* Will be 2 */</span>

<span class="predefined-type">Set</span>&lt;<span class="predefined-type">Position</span>&gt; poss = shape.positionSet();
<span class="comment">/* contains the 4 positions */</span>

<span class="type">int</span> size = shape.size();
<span class="comment">/* Will be 4 */</span></code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="extracting_subtensors"><a class="anchor" href="#extracting_subtensors"></a>Extracting Subtensors</h3>
<div class="paragraph">
<p>One very common structural operation is extracting sub-tensors from a tensor:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Tensor&lt;<span class="predefined-type">Double</span>&gt; sfDegrees = from(degrees).extract(SF);</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will result in a 1-dimensional tensor, only containing coordinates of type <code>Time</code>. The complementary operation to this is called <em>merging</em> tensors.</p>
</div>
<div class="paragraph">
<p>\textbf{Note:} while in the <code>get</code> method, the number of coordinates always has to exactly match the dimensionality of the tensor (otherwise the method will throw), the \code{extract} method takes any subset of the dimensions as argument; the \code{get} method returns the values of the tensor, while the \code{extract} method returns again a tensor. This implies that if coordinates for all dimensions are provided as arguments for the extract method, then a zero-dimensional tensor is returned. The returned tensor can be empty in case no elements exist at the extracted coordinates.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="mathematical_operations"><a class="anchor" href="#mathematical_operations"></a>Mathematical Operations</h2>
<div class="sectionbody">
<div class="paragraph">
<p>One important motivation to use tensors is of course to have simple and intuitive ways to perform mathematical operations on them. While the structural operations - as described up to now - can be performed on tensors of any value types, it is clear that mathematical operations can be only done with tensor values of particular types.</p>
</div>
<div class="sect2">
<h3 id="mathematical_structures"><a class="anchor" href="#mathematical_structures"></a>Mathematical Structures</h3>
<div class="paragraph">
<p>Tensorics does not strictly restrict the types on which mathematical operations can be performed, but provides an extension mechanism through which - in principle - the mathematical capabilities can be added for any value type. In practice this makes only sense (and is only necessary) for a limited number of value types. The extension mechanism requires to provide (with $a,b,c$ being tensor values):</p>
</div>
<hr>
<div class="ulist">
<ul>
<li>
<p>Two binary operations, addition ( + ) and multiplication ( * ) with the following properties:</p>
</li>
<li>
<p>both, + and * are associative: $a + (b + c) = (a + b) + c$; $a * (b * c) = (a * b) * c$.</p>
</li>
<li>
<p>both, + and * have an identity element (Called '0' for +, '1' for * ): $a + 0 = a$; $a * 1 = a$.</p>
</li>
<li>
<p>both, + and * have an inverse element (Called '-a' for +, '1/a' for * ): $a + (-a) = 0$; $a * 1/a = 1$.</p>
</li>
<li>
<p>both, + and * are commutative: $a + b = b + a$; $a * b = b * a$.</p>
</li>
<li>
<p>* is distributive over +: $a * (b + c) = a * b + a * c$.</p>
</li>
</ul>
</div>
<hr>
<div class="paragraph">
<p>Mathematically speaking, the two operations form the algebraic structure of a <em>field</em> \cite{wikipedia-field} over the tensor values <code>&lt;V&gt;</code>:
---
* Two additional binary operations: Power ($a^b$) and Root ($\sqrt[b]{a}$).
* A conversion function of the tensor values to and from doubles.
---
If these operations are provided to generic support classes of \tensorics{}, then all the manipulations based in the following will be available by inheriting from these support classes. The biggest advantage of the approach used in tensorics for defining a field (and using external methods for calculations - not methods of the field elements) is that it (technically) does not impose any constraints on the value type and thus avoids e.g. wrapper objects as necessary in the field-implementations of other math libraries (e.g. Apache Commons Math \cite{apache-commons-math}).</p>
</div>
<div class="paragraph">
<p>Out of the box, tensorics currently provides an implementation of these requirements for doubles. To simplify these very frequently required operations, it provides also a convenience class (\code{TensoricsDoubles}) with static delegation methods to the support classes. Such convenience will not be available out of the box for custom value types, but can be easily added in a similar way. Whenever there is trailing method call in the following examples, we will assume that it is a static method from the class \code{TensoricDoubles}.</p>
</div>
<div class="sect3">
<h4 id="unary_operations"><a class="anchor" href="#unary_operations"></a>Unary Operations</h4>
<div class="paragraph">
<p>Next to operations on tensors, the support classes also provide convenience operations for iterables. For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Iterable</span>&lt;<span class="predefined-type">Double</span>&gt; v = <span class="predefined-type">Arrays</span>.asList(<span class="float">1.0</span>, <span class="float">2.0</span>);
<span class="predefined-type">Iterable</span>&lt;<span class="predefined-type">Double</span>&gt; negv = negativeOf(v);
<span class="predefined-type">Double</span> vsize = sizeOf(v);

Tensor&lt;<span class="predefined-type">Double</span>&gt; t; <span class="comment">/* creation omitted */</span>
Tensor&lt;<span class="predefined-type">Double</span>&gt; negt = negativeOf(t);
<span class="predefined-type">Double</span> tsize = sizeOf(t);</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="basic_statistics"><a class="anchor" href="#basic_statistics"></a>Basic Statistics</h4>
<div class="paragraph">
<p>Some very simple statistical methods are provided out of the box. For iterables, the results are simply of type of the elements of the iterable:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="predefined-type">Iterable</span>&lt;<span class="predefined-type">Double</span>&gt; v = <span class="predefined-type">Arrays</span>.asList(<span class="float">1.0</span>, <span class="float">2.0</span>);
<span class="predefined-type">Double</span> avg = averageOf(v);
<span class="predefined-type">Double</span> sum = sumOf(v);
<span class="predefined-type">Double</span> rms = rmsOf(v);</code></pre>
</div>
</div>
<div class="paragraph">
<p>On the other hand, for tensors the application of statistical operations is usually done only in one dimension. This corresponds to a reduction of the tensor by one dimension. The provided fluent API reflects this (continuing our example from before):</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="comment">/* All these return Tensor&lt;Double&gt;: */</span>
reduce(degrees).byAveragingOver(<span class="predefined-type">Time</span>.class);
reduce(degrees).byRmsOver(<span class="predefined-type">Time</span>.class);
reduce(degrees).bySummingOver(<span class="predefined-type">Time</span>.class);</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="binary_operations"><a class="anchor" href="#binary_operations"></a>Binary Operations</h4>
<div class="paragraph">
<p>Calculating of operations between two tensors, finally makes the most use. These operations all start using the \code{TensoricDoubles.calculate(&#8230;&#8203;)} method:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="comment">/* degrees and offset are Tensor&lt;Double&gt; */</span>

calculate(degrees).plus(offset);
calculate(degrees).minus(offset);
calculate(degrees).elementTimes(other);
calculate(degrees).elementDividedBy(other);

<span class="comment">/* All these return Tensor&lt;Double&gt; */</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Here both, the left and right operands are assumed to be tensors. However, bare values are also supported on both sides and will be implicitly be converted to scalars. The four above-mentioned operations are the simplest ones, as they are based on element wise operations: Each element in the left tensor only requires the corresponding element in the right tensor to produce the corresponding element in the resulting tensor. However, this needs some other considerations: What happens if the two operands have different shapes? This problem can be treated in two stages, which are called \emph{broadcasting} and \emph{reshaping} in \tensorics{}. They are explained in the following two sections. \Tensorics{} has a very modular way to treat such cases: Different strategies can be used (and even implemented) by the user in special cases. If nothing is specified, a sensitive default will be used.</p>
</div>
</div>
<div class="sect3">
<h4 id="reshaping"><a class="anchor" href="#reshaping"></a>Reshaping</h4>
<div class="paragraph">
<p>This is the simpler of the two possible shape-inconsistencies: It means that both tensors in question have the same dimensions, but they have values for different positions (e.g. one has less entries than the other).
The default behaviour for this case is, that the resulting tensor will have only values for the positions, which are contained in each of the tensor (The intersection of the position set).</p>
</div>
</div>
<div class="sect3">
<h4 id="broadcasting"><a class="anchor" href="#broadcasting"></a>Broadcasting</h4>
<div class="paragraph">
<p>The term \emph{broadcasting} is borrowed from the python library \emph{numpy} \cite{numpy-github}. While the underlaying principle is very similar to the numpy one, there are several essential difference which comes from the fact that numpy uses multi-dimensional arrays with integer indices, while tensorics identifies its dimensions by classes: The default broadcasting strategy in \tensorics{} broadcasts all dimensions which are \emph{not} available in one tensor to the shape of the second tensor. In other words, a dimension which is not present in one, will be added to the other tensor and all coordinate values of the respective dimension will potentially be combined with all the positions of the other tensor. For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Tensor&lt;<span class="predefined-type">Double</span>&gt; temps =
  builder(<span class="predefined-type">Time</span>.class)
    .put(at(T1), <span class="float">10.5</span>)
    .put(at(T2), <span class="float">12.2</span>)
    .build();

Tensor&lt;<span class="predefined-type">Double</span>&gt; offsets =
  builder(City.class)
    .put(at(SF), <span class="float">2.0</span>)
    .put(at(LA), <span class="float">7.0</span>)
    .build();

Tensor&lt;<span class="predefined-type">Double</span>&gt; result = calculate(temps).elementTimes(factors);
<span class="comment">/* Will contain 4 positions: (SF, T1), (SF, T2), (LA, T1), (LA, T2) */</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The result will be exactly the same tensor as constructed in \lstref{buildingATensor}. When performing binary operations, the two operands are first both broadcasted and then reshaped. This ensures that the dimensions are correct and then that all the relevant elements operate on their corresponding partners.</p>
</div>
</div>
<div class="sect3">
<h4 id="inner_product"><a class="anchor" href="#inner_product"></a>Inner Product</h4>
<div class="paragraph">
<p>This very particular multiplication of two tensors is basically the generalization of the matrix multiplication. The syntax is as simple as it can be:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">calculate(degrees).times(other);</code></pre>
</div>
</div>
<div class="paragraph">
<p>To have this yield the expected results, co- and contra-variant dimensions have to be distinguished. In \tensorics{}, this distinction is achieved by the following mechanism: By default, coordinates are assumed to be contravariant. Covariant coordinates are forced to inherit from the class \code{Covariant&lt;C&gt;}, where the generic parameter \code{&lt;C&gt;} is the type of the corresponding contravariant coordinate. Detailed information about this can be found in the tensorics source code documentation \cite{tensorics-javadoc}.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="physical_quantities_and_units"><a class="anchor" href="#physical_quantities_and_units"></a>Physical Quantities and Units</h3>
<div class="paragraph">
<p>Another very common problem in scientific applications is the proper treatment of units. At the current stage, \tensorics{} currently uses internally an external library for this purpose (JScience \cite{jscience}). However, as this library is not actively maintained anymore, it is foreseen to replace this implementation either by a different library or an internal implementation of physical quantities.</p>
</div>
<div class="paragraph">
<p>For this reason, \tensorics{} already provides its own abstraction of units. A physical unit is represented by the class \code{Unit} and a value-unit pair is represented by the class \code{QuantifiedValue}. Factory methods for quantified values are available in the \code{Tensorics} class. Convenience overrides are provided which support both \tensorics{} internal unit objects and JScience instances of units. Operations are available in the support classes for the corresponding value types, like for doubles e.g. in the class \code{TensoricDoubles}. With this, operations like the following are possible:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">QuantifiedValue&lt;<span class="predefined-type">Double</span>&gt; distance = Tensorics.quantityOf(<span class="float">10.0</span>, SI.METER);

QuantifiedValue&lt;<span class="predefined-type">Double</span>&gt; time = Tensorics.quantityOf(<span class="float">5.0</span>, SI.SECOND);

QuantifiedValue&lt;<span class="predefined-type">Double</span>&gt; speed = calculate(distance).dividedBy(time);
<span class="comment">/* results in 2 m/s */</span>

<span class="predefined-type">Double</span> value = speed.value(); <span class="comment">// 2.0</span>
Unit unit = speed.unit(); <span class="comment">// m/s</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Also support methods to work with tensors of quantified values are provided, e.g.:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">Tensor&lt;QuantifiedValue&lt;<span class="predefined-type">Double</span>&gt;&gt; measurement;
Tensor&lt;QuantifiedValue&lt;<span class="predefined-type">Double</span>&gt;&gt; reference;
<span class="comment">/* construction omitted */</span>

Tensor&lt;QuantifiedValue&lt;<span class="predefined-type">Double</span>&gt;&gt; difference = calculate(measurement).minus(reference);</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="error_and_validity_propagation"><a class="anchor" href="#error_and_validity_propagation"></a>Error and Validity Propagation</h3>
<div class="paragraph">
<p>Especially when using tensors for measured values, it is important to understand the errors after a series of calculations. Further, it is can be that individual points in a tensor contain invalid data. It then makes no sense to do calculations with them. \Tensorics{} provides dedicated mechanisms for this cases. The \code{QuantifiedValue}s contain two additional fields: a (boolean) validity flag and an optional value for an error (uncertainty). All the operations on quantified values (and on tensors of quantified values) take this fields into account. The exact behavior can again be configured by the use of explicit strategies. The defaults are:
---
* If an invalid value is used in a calculation, then the resulting value will be invalid.
* The values involved in the calculations will be treated as independent variables and the error is propagated to the resulting value accordingly \cite{error-propagation-wikipedia}.
---</p>
</div>
<div class="paragraph">
<p>Comparisons between quantities take into account their associated errors assuming Gaussian statistics. The confidence level is 95\% unless specified otherwise. This allows to conveniently check if a quantity is significantly less, equal, or greater than another. For example, $90 \pm 1 \mathrm{m}$ is significantly less than $100 \pm 10  \mathrm{m}$ at a confidence level of 68\% but not at 95\%.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">QuantifiedValue&lt;<span class="predefined-type">Double</span>&gt; q90pm1 = quantityOf(<span class="float">90.0</span>, METER).withError(<span class="float">1.0</span>);
QuantifiedValue&lt;<span class="predefined-type">Double</span>&gt; q100pm10 = quantityOf(<span class="float">100.0</span>, METER).withError(<span class="float">10.0</span>);

<span class="comment">/* false at 95% confidence (default): */</span>
testIf(q90pm1).isLessThan(q100pm10);

<span class="comment">/* true at 68% confidence: */</span>
with(confidenceLevelOf(<span class="float">0.68</span>)).testIf(q90pm1).isLessThan(q100pm10);</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="tensorbacked_domain_objects"><a class="anchor" href="#tensorbacked_domain_objects"></a>Tensorbacked Domain Objects</h3>
<div class="paragraph">
<p>While working with tensors gives all the flexibility of transformations and calculations, very often it is desirable to give more meaning to objects. Usually one would create dedicated domain objects in these cases. However, this would mean giving up all the convenient support methods. To combine the best of both approaches, \tensorics{} provides a built-in mechanism for creating domain objects which wrap tensors inside and allow almost the same calculations and transformations as plain tensors. These objects are called \code{Tensorbacked}s and can be defined by the user as required. The simplest way to do so is to inherit from \code{AbstractTensorbacked}. An important property of tensorbacked objects is that each of them has a fixed set of dimensions, which are defined through the dedicated annotation \code{@Dimensions}. For example, if one would like to define some domain object that contains temperatures, one could do so by</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java"><span class="annotation">@Dimensions</span>({<span class="predefined-type">Time</span>.class, City.class})
<span class="directive">public</span> <span class="type">class</span> <span class="class">TemperatureMap</span>
    <span class="directive">extends</span> AbstractTensorbacked&lt;<span class="predefined-type">Double</span>&gt; {
    <span class="comment">/* empty (except a constructor) */</span>
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Instances of these classes can then be created using simply an existing tensor or a builder. Calculations can be performed like with bare tensors.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="CodeRay highlight"><code data-lang="java">TemperatureMap measured = Tensorics.construct(TemperatureMap.class).from(degrees);

TemperatureMap reference = Tensorics
    .builderFor(TemperatureMap.class)
      .put(at(SF, T1), <span class="float">10.0</span>)
      .build();

TemperatureMap diff = DoubleTensorics.calculate(measured).minus(reference);</code></pre>
</div>
</div>
<div class="paragraph">
<p>When using a builder, the dimensions do not have to be given explicitly, as they are already defined through the annotation.</p>
</div>
</div>
<div class="sect2">
<h3 id="expression_language"><a class="anchor" href="#expression_language"></a>Expression Language</h3>
<div class="paragraph">
<p>All the examples in the previous sections described directly Java executable code. In addition to this, \tensorics{} provides a Java internal domain specific language (DSL) to only describe calculation steps using the same operations as described before. This DSL does not directly execute the calculations, but instead creates an expression tree, which can be evaluated (resolved) in a separate step. Since these expressions can be resolved in different contexts, this can e.g. be used for subscription based online evaluation (e.g. processing data from devices) or processing logged data. This expression language is one of the cornerstones of a recently developed online analysis framework. More details can be found in the corresponding publication \cite{analysis-framework}.</p>
</div>
<div class="paragraph">
<p>Last build:		2018-04-17 20:22:13 CEST</p>
</div>
</div>
</div>
</div>
      </div>
    </div>
  </div>

  <footer>Tensorics is an Open Source project developed at CERN under <a href="https://raw.githubusercontent.com/tensorics/tensorics-core/master/LICENSE.txt">Apache 2.0</a> license.</footer>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
<script src="/js/toc.js"></script>
</body>
</html>
